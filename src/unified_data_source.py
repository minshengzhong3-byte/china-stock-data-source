#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€æ•°æ®æºæ¨¡å— - Unified Data Source Module

æ•´åˆå¤šä¸ªAè‚¡æ•°æ®æºï¼Œæä¾›ç»Ÿä¸€çš„æ•°æ®è·å–æ¥å£ã€‚
æ”¯æŒæ™ºèƒ½æ•…éšœè½¬ç§»ã€æ•°æ®ç¼“å­˜ã€è´¨é‡éªŒè¯ã€‚
ä¸“ä¸ºé‡åŒ–äº¤æ˜“å’ŒAIæ¨¡å‹è®¾è®¡ã€‚

Integrates multiple A-share data sources with unified interface.
Supports intelligent failover, data caching, and quality validation.
Designed for quantitative trading and AI models.

Author: minshengzhong3-byte
GitHub: https://github.com/minshengzhong3-byte/china-stock-data-source
License: MIT
"""

import pandas as pd
import numpy as np
import requests
import time
import logging
from datetime import datetime, timedelta
from typing import Optional, Dict, List, Any, Union
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from functools import wraps
import json
import os

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DataSourceError(Exception):
    """æ•°æ®æºå¼‚å¸¸åŸºç±»"""
    pass

class ConnectionError(DataSourceError):
    """è¿æ¥å¼‚å¸¸"""
    pass

class DataQualityError(DataSourceError):
    """æ•°æ®è´¨é‡å¼‚å¸¸"""
    pass

class UnifiedDataSource:
    """
    ç»Ÿä¸€æ•°æ®æºç±» - æ•´åˆå¤šä¸ªAè‚¡æ•°æ®æº
    
    Features:
    - æ™ºèƒ½æ•…éšœè½¬ç§»ï¼šè‡ªåŠ¨åˆ‡æ¢å¯ç”¨æ•°æ®æº
    - æ•°æ®ç¼“å­˜ï¼šå‡å°‘é‡å¤è¯·æ±‚ï¼Œæé«˜æ€§èƒ½
    - è´¨é‡éªŒè¯ï¼šè‡ªåŠ¨æ£€æµ‹å’Œè¿‡æ»¤å¼‚å¸¸æ•°æ®
    - å¹¶å‘å®‰å…¨ï¼šæ”¯æŒå¤šçº¿ç¨‹ç¯å¢ƒ
    - AIå‹å¥½ï¼šç®€æ´çš„APIè®¾è®¡ï¼Œé€‚åˆæ¨¡å‹é›†æˆ
    """
    
    def __init__(self, 
                 cache_expire_minutes: int = 5,
                 max_retries: int = 3,
                 timeout: int = 10,
                 enable_cache: bool = True,
                 data_sources: Optional[List[str]] = None):
        """
        åˆå§‹åŒ–ç»Ÿä¸€æ•°æ®æº
        
        Args:
            cache_expire_minutes: ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            enable_cache: æ˜¯å¦å¯ç”¨ç¼“å­˜
            data_sources: æ•°æ®æºä¼˜å…ˆçº§åˆ—è¡¨ï¼Œé»˜è®¤ä¸º['abu', 'ashare']
        """
        self.cache_expire_minutes = cache_expire_minutes
        self.max_retries = max_retries
        self.timeout = timeout
        self.enable_cache = enable_cache
        
        # æ•°æ®æºä¼˜å…ˆçº§
        self.data_sources = data_sources or ['abu', 'ashare']
        
        # ç¼“å­˜å’Œé”
        self._cache = {}
        self._cache_lock = threading.RLock()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self._stats = {
            'requests': 0,
            'cache_hits': 0,
            'errors': 0,
            'source_usage': {source: 0 for source in self.data_sources}
        }
        
        # åˆå§‹åŒ–æ•°æ®æº
        self._init_data_sources()
        
        logger.info(f"UnifiedDataSource initialized with sources: {self.data_sources}")
    
    def _init_data_sources(self):
        """åˆå§‹åŒ–æ•°æ®æºå®ä¾‹"""
        self._source_instances = {}
        
        for source in self.data_sources:
            try:
                if source == 'abu':
                    from .abu_source import AbuDataSource
                    self._source_instances[source] = AbuDataSource()
                elif source == 'ashare':
                    from .ashare_source import AshareDataSource
                    self._source_instances[source] = AshareDataSource()
                else:
                    logger.warning(f"Unknown data source: {source}")
            except ImportError as e:
                logger.warning(f"Failed to import {source} data source: {e}")
            except Exception as e:
                logger.error(f"Failed to initialize {source} data source: {e}")
    
    def _get_cache_key(self, method: str, *args, **kwargs) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_parts = [method] + [str(arg) for arg in args]
        for k, v in sorted(kwargs.items()):
            key_parts.append(f"{k}={v}")
        return "|".join(key_parts)
    
    def _get_from_cache(self, cache_key: str) -> Optional[Any]:
        """ä»ç¼“å­˜è·å–æ•°æ®"""
        if not self.enable_cache:
            return None
            
        with self._cache_lock:
            if cache_key in self._cache:
                data, timestamp = self._cache[cache_key]
                if time.time() - timestamp < self.cache_expire_minutes * 60:
                    self._stats['cache_hits'] += 1
                    return data
                else:
                    # ç¼“å­˜è¿‡æœŸï¼Œåˆ é™¤
                    del self._cache[cache_key]
        return None
    
    def _set_cache(self, cache_key: str, data: Any):
        """è®¾ç½®ç¼“å­˜"""
        if not self.enable_cache:
            return
            
        with self._cache_lock:
            self._cache[cache_key] = (data, time.time())
    
    def _validate_symbol(self, symbol: str) -> str:
        """éªŒè¯å’Œæ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç """
        if not symbol:
            raise ValueError("è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º")
        
        # ç§»é™¤ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
        symbol = str(symbol).strip().upper()
        
        # æ ‡å‡†åŒ–ä¸º6ä½æ•°å­—æ ¼å¼
        if symbol.isdigit():
            symbol = symbol.zfill(6)
        elif '.' in symbol:
            # å¤„ç†å¸¦åç¼€çš„æ ¼å¼ï¼Œå¦‚ 000001.SZ
            symbol = symbol.split('.')[0].zfill(6)
        
        # éªŒè¯æ ¼å¼
        if not (symbol.isdigit() and len(symbol) == 6):
            raise ValueError(f"æ— æ•ˆçš„è‚¡ç¥¨ä»£ç æ ¼å¼: {symbol}")
        
        return symbol
    
    def _validate_data_quality(self, data: Any, data_type: str) -> bool:
        """éªŒè¯æ•°æ®è´¨é‡"""
        if data is None:
            return False
        
        try:
            if data_type == 'realtime':
                # éªŒè¯å®æ—¶æ•°æ®
                required_fields = ['price']
                if isinstance(data, dict):
                    return all(field in data and data[field] is not None for field in required_fields)
                return False
            
            elif data_type == 'history':
                # éªŒè¯å†å²æ•°æ®
                if isinstance(data, pd.DataFrame) and not data.empty:
                    required_columns = ['open', 'high', 'low', 'close']
                    return all(col in data.columns for col in required_columns)
                return False
            
        except Exception as e:
            logger.warning(f"Data quality validation error: {e}")
            return False
        
        return True
    
    def get_realtime_price(self, symbol: str) -> Optional[Dict[str, Any]]:
        """
        è·å–è‚¡ç¥¨å®æ—¶ä»·æ ¼ä¿¡æ¯
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚'000001'ï¼‰
        
        Returns:
            åŒ…å«å®æ—¶ä»·æ ¼ä¿¡æ¯çš„å­—å…¸ï¼Œå¤±è´¥æ—¶è¿”å›None
            {
                'symbol': '000001',
                'price': 10.5,
                'change': 0.2,
                'change_percent': 1.94,
                'volume': 1000000,
                'timestamp': '2024-01-15 15:00:00'
            }
        """
        try:
            symbol = self._validate_symbol(symbol)
            cache_key = self._get_cache_key('realtime', symbol)
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached_data = self._get_from_cache(cache_key)
            if cached_data is not None:
                return cached_data
            
            # ä»æ•°æ®æºè·å–
            self._stats['requests'] += 1
            
            for source_name in self.data_sources:
                if source_name not in self._source_instances:
                    continue
                
                try:
                    source = self._source_instances[source_name]
                    data = source.get_realtime_price(symbol)
                    
                    if self._validate_data_quality(data, 'realtime'):
                        self._stats['source_usage'][source_name] += 1
                        self._set_cache(cache_key, data)
                        return data
                    
                except Exception as e:
                    logger.warning(f"Failed to get realtime price from {source_name}: {e}")
                    continue
            
            # æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥
            self._stats['errors'] += 1
            logger.error(f"Failed to get realtime price for {symbol} from all sources")
            return None
            
        except Exception as e:
            self._stats['errors'] += 1
            logger.error(f"Error in get_realtime_price: {e}")
            return None
    
    def get_history_data(self, 
                        symbol: str, 
                        start_date: str, 
                        end_date: Optional[str] = None,
                        period: str = 'daily') -> Optional[pd.DataFrame]:
        """
        è·å–è‚¡ç¥¨å†å²æ•°æ®
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼'YYYY-MM-DD'
            end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼'YYYY-MM-DD'ï¼Œé»˜è®¤ä¸ºä»Šå¤©
            period: æ•°æ®å‘¨æœŸï¼Œæ”¯æŒ'daily', 'weekly', 'monthly'
        
        Returns:
            åŒ…å«å†å²æ•°æ®çš„DataFrameï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        try:
            symbol = self._validate_symbol(symbol)
            
            if end_date is None:
                end_date = datetime.now().strftime('%Y-%m-%d')
            
            cache_key = self._get_cache_key('history', symbol, start_date, end_date, period)
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached_data = self._get_from_cache(cache_key)
            if cached_data is not None:
                return cached_data
            
            # ä»æ•°æ®æºè·å–
            self._stats['requests'] += 1
            
            for source_name in self.data_sources:
                if source_name not in self._source_instances:
                    continue
                
                try:
                    source = self._source_instances[source_name]
                    data = source.get_history_data(symbol, start_date, end_date, period)
                    
                    if self._validate_data_quality(data, 'history'):
                        self._stats['source_usage'][source_name] += 1
                        self._set_cache(cache_key, data)
                        return data
                    
                except Exception as e:
                    logger.warning(f"Failed to get history data from {source_name}: {e}")
                    continue
            
            # æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥
            self._stats['errors'] += 1
            logger.error(f"Failed to get history data for {symbol} from all sources")
            return None
            
        except Exception as e:
            self._stats['errors'] += 1
            logger.error(f"Error in get_history_data: {e}")
            return None
    
    def normalize_symbol(self, symbol: str) -> str:
        """
        æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç æ ¼å¼
        
        Args:
            symbol: åŸå§‹è‚¡ç¥¨ä»£ç 
        
        Returns:
            æ ‡å‡†åŒ–åçš„6ä½è‚¡ç¥¨ä»£ç 
        """
        return self._validate_symbol(symbol)
    
    def test_all_sources(self) -> Dict[str, bool]:
        """
        æµ‹è¯•æ‰€æœ‰æ•°æ®æºçš„å¯ç”¨æ€§
        
        Returns:
            å„æ•°æ®æºçš„å¯ç”¨æ€§çŠ¶æ€
        """
        results = {}
        test_symbol = '000001'  # ä½¿ç”¨å¹³å®‰é“¶è¡Œä½œä¸ºæµ‹è¯•
        
        for source_name in self.data_sources:
            if source_name not in self._source_instances:
                results[source_name] = False
                continue
            
            try:
                source = self._source_instances[source_name]
                data = source.get_realtime_price(test_symbol)
                results[source_name] = self._validate_data_quality(data, 'realtime')
            except Exception as e:
                logger.warning(f"Test failed for {source_name}: {e}")
                results[source_name] = False
        
        return results
    
    def get_usage_stats(self) -> Dict[str, Any]:
        """
        è·å–ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        with self._cache_lock:
            cache_size = len(self._cache)
        
        return {
            **self._stats,
            'cache_size': cache_size,
            'cache_hit_rate': self._stats['cache_hits'] / max(self._stats['requests'], 1) * 100
        }
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        with self._cache_lock:
            self._cache.clear()
        logger.info("Cache cleared")

# å…¨å±€å®ä¾‹
_default_instance = None
_instance_lock = threading.Lock()

def get_default_instance() -> UnifiedDataSource:
    """è·å–é»˜è®¤çš„UnifiedDataSourceå®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _default_instance
    if _default_instance is None:
        with _instance_lock:
            if _default_instance is None:
                _default_instance = UnifiedDataSource()
    return _default_instance

# ä¾¿æ·å‡½æ•°
def get_stock_data(symbol: str, 
                  start_date: str, 
                  end_date: Optional[str] = None,
                  period: str = 'daily') -> Optional[pd.DataFrame]:
    """
    è·å–è‚¡ç¥¨å†å²æ•°æ®ï¼ˆä¾¿æ·å‡½æ•°ï¼‰
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        period: æ•°æ®å‘¨æœŸ
    
    Returns:
        å†å²æ•°æ®DataFrame
    """
    return get_default_instance().get_history_data(symbol, start_date, end_date, period)

def get_realtime_price(symbol: str) -> Optional[Dict[str, Any]]:
    """
    è·å–è‚¡ç¥¨å®æ—¶ä»·æ ¼ï¼ˆä¾¿æ·å‡½æ•°ï¼‰
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
    
    Returns:
        å®æ—¶ä»·æ ¼ä¿¡æ¯å­—å…¸
    """
    return get_default_instance().get_realtime_price(symbol)

def main():
    """ä¸»å‡½æ•° - ç”¨äºæµ‹è¯•"""
    print("ğŸš€ China Stock Data Source - æµ‹è¯•æ¨¡å¼")
    print("=" * 50)
    
    # åˆ›å»ºæ•°æ®æºå®ä¾‹
    ds = UnifiedDataSource()
    
    # æµ‹è¯•æ•°æ®æºçŠ¶æ€
    print("ğŸ“Š æµ‹è¯•æ•°æ®æºçŠ¶æ€...")
    status = ds.test_all_sources()
    for source, available in status.items():
        status_icon = "âœ…" if available else "âŒ"
        print(f"  {status_icon} {source}: {'å¯ç”¨' if available else 'ä¸å¯ç”¨'}")
    
    # æµ‹è¯•å®æ—¶æ•°æ®
    print("\nğŸ’° æµ‹è¯•å®æ—¶æ•°æ®è·å–...")
    test_symbols = ['000001', '000002', '600000']
    for symbol in test_symbols:
        try:
            price_data = ds.get_realtime_price(symbol)
            if price_data:
                print(f"  ğŸ“ˆ {symbol}: {price_data.get('price', 'N/A')} ({price_data.get('change_percent', 'N/A')}%)")
            else:
                print(f"  âŒ {symbol}: è·å–å¤±è´¥")
        except Exception as e:
            print(f"  âŒ {symbol}: é”™è¯¯ - {e}")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š ä½¿ç”¨ç»Ÿè®¡:")
    stats = ds.get_usage_stats()
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    print("\nâœ… æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main()